{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import tiktoken\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "from evaluation_funcs import load_txt_files_to_df\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_metric\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac663bc34744ca59a228b1f3d1276ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_openai_batch_result(batch_file, jsonl_file):\n",
    "\n",
    "    \"\"\" \n",
    "    Small function to help keep the openai batch process clean. downloads the batch file and saves it as a jsonl file\n",
    "    \"\"\"\n",
    "\n",
    "    result = client.files.content(batch_file).content\n",
    "\n",
    "    with open(jsonl_file, 'wb') as file:\n",
    "        file.write(result)\n",
    "\n",
    "\n",
    "def convert_opanai_jsonl_to_df(jsonl_file):\n",
    "\n",
    "    \"\"\" \n",
    "    Loads a jsonl file returned from the openai batch process. Returns a dataframe containing only the most useful information\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    with open(jsonl_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parsing the JSON string into a dict and appending to the list of results\n",
    "            json_object = json.loads(line.strip())\n",
    "            necessary_data = {\n",
    "                'id': json_object['custom_id'],\n",
    "                'post_lm_text': json_object['response']['body']['choices'][0]['message']['content']\n",
    "            }\n",
    "            necessary_data.update(json_object['response']['body']['usage'])\n",
    "            results.append(necessary_data)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def pre_evaluation_processing(df, ground_truth_df, post_lm_text, gt_text ):\n",
    "    df['id'] = df['id'].str.replace('filename_', '')\n",
    "\n",
    "    df = df.merge(ground_truth_df.set_index('file_name'), left_on = 'id', right_index = True)\n",
    "    #df['post_lm_text2'] = df['post_lm_text'].apply(extract_first_match)\n",
    "    df[post_lm_text] = df[post_lm_text].str.replace(\"\\n\", \"\").str.lower()\n",
    "    df[gt_text] = df[gt_text].str.replace(\"\\n\", \"\").str.lower()\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def evaluate_model(df, metric_obj, gt_text, post_lm_text):\n",
    "\n",
    "    \"\"\" \n",
    "    Uses a huggingface metric to evaluate the results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate CER for each pair\n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        ground_truth_text = row[gt_text]\n",
    "        response_text = row[post_lm_text]\n",
    "        result = metric_obj.compute(predictions=[response_text], references=[ground_truth_text])\n",
    "        results.append(result)\n",
    "\n",
    "    df['cer'] = results\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the silverset\n",
    "\n",
    "- set seed\n",
    "- for each file\n",
    "    - load file\n",
    "    - remove all entries greater than smaller than 100 tokens, above acceptable noise\n",
    "\n",
    "- concatenate to single data frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ncse_base_1.parquet',\n",
       " 'ncse_base_6.parquet',\n",
       " 'ncse_base_0.parquet',\n",
       " 'ncse_base_5.parquet',\n",
       " 'ncse_base_2.parquet',\n",
       " 'ncse_base_4.parquet',\n",
       " 'ncse_base_3.parquet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data/ncse_text_chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_df = pd.read_parquet('./data/ncse_text_chunks2/'+'ncse_base_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = './data/transcripts/transcription_files'\n",
    "\n",
    "files_in_directory =  set(os.listdir(target_dir))\n",
    "\n",
    "all_data_df = []\n",
    "\n",
    "for file in os.listdir('./data/ncse_text_chunks'):\n",
    "\n",
    "     temp_df = pd.read_parquet('./data/ncse_text_chunks/'+file)\n",
    "     temp_df['entire_article'] = temp_df[['continuation_from_id','continuation_to_id']].isna().sum(axis = 1)==2\n",
    "     temp_df =  temp_df.loc[temp_df['total_tokens']>100,['id', 'total_tokens', 'symbol_fract', 'entire_article','publication_id', 'file_name', 'content_html']]\n",
    "     all_data_df.append(temp_df)\n",
    "\n",
    "all_data_df = pd.concat(all_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proper tokenization is important as llama3 has 3x the vocabulary so will produce fewer tokens for a given text than llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_x_tokens(text, tokenizer, max_tokens = 1000):\n",
    "    \"\"\"\n",
    "    Extract the first 1000 tokens from a string using the hugginface tokenizer. It ensures that\n",
    "    the number of tokens in each string does not exceed the limit for a specific model or\n",
    "    finetuning budget\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input string.\n",
    "    tokenizer: The tokenizer object for the model of interest\n",
    "    max_tokens: The maximum number of tokens\n",
    "\n",
    "    Returns:\n",
    "    str: The string containing the first 1000 tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer.encode(text)\n",
    "\n",
    "    # Extract the first x tokens\n",
    "    first_1000_tokens = tokens[:max_tokens]\n",
    "\n",
    "    # Decode the tokens back to string\n",
    "    truncated_text = tokenizer.decode(first_1000_tokens)\n",
    "    #re-calc total tokens in text\n",
    "    total_tokens = len(first_1000_tokens)\n",
    "\n",
    "    return truncated_text, total_tokens\n",
    "\n",
    "random.seed(12335)\n",
    "#remove the transcribed data then sample. This is to keep the test set pure\n",
    "sampled_data = all_data_df.loc[~all_data_df['file_name'].isin(os.listdir('./data/transcripts/transcription_files')),:].sample(11000) #11000\n",
    "#reduce to a maximum token size of 1000\n",
    "sampled_data[['content_html', 'total_tokens_llama']] = sampled_data['content_html'].apply(lambda x: pd.Series(extract_first_x_tokens(x, tokenizer)))\n",
    "omni_tokenizer = tiktoken.get_encoding(\"o200k_base\")\n",
    "sampled_data[['content_html_drop', 'total_tokens_omni']] = sampled_data['content_html'].apply(lambda x: pd.Series(extract_first_x_tokens(x, omni_tokenizer, max_tokens=10000)))\n",
    "sampled_data = sampled_data.drop('content_html_drop', axis = 1)\n",
    "sampled_data.to_parquet('./data/silver_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = pd.read_parquet('./data/silver_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>symbol_fract</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>total_tokens_llama</th>\n",
       "      <th>total_tokens_omni</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.100000e+04</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.505863e+05</td>\n",
       "      <td>915.475909</td>\n",
       "      <td>0.217735</td>\n",
       "      <td>24.261091</td>\n",
       "      <td>593.797364</td>\n",
       "      <td>588.017000</td>\n",
       "      <td>1.004150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.945087e+05</td>\n",
       "      <td>907.276629</td>\n",
       "      <td>0.133610</td>\n",
       "      <td>3.140817</td>\n",
       "      <td>340.439513</td>\n",
       "      <td>334.197164</td>\n",
       "      <td>0.022444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.078010e+05</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.754491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.776925e+05</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>0.144096</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.994986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.570765e+05</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>0.178465</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>554.000000</td>\n",
       "      <td>1.005025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.213248e+05</td>\n",
       "      <td>1283.250000</td>\n",
       "      <td>0.246445</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>979.000000</td>\n",
       "      <td>1.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.073158e+06</td>\n",
       "      <td>10668.000000</td>\n",
       "      <td>2.920792</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.397260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  total_tokens  symbol_fract  publication_id  \\\n",
       "count  1.100000e+04  11000.000000  11000.000000    11000.000000   \n",
       "mean   7.505863e+05    915.475909      0.217735       24.261091   \n",
       "std    1.945087e+05    907.276629      0.133610        3.140817   \n",
       "min    4.078010e+05    101.000000      0.059829       19.000000   \n",
       "25%    5.776925e+05    257.000000      0.144096       20.000000   \n",
       "50%    7.570765e+05    560.000000      0.178465       26.000000   \n",
       "75%    9.213248e+05   1283.250000      0.246445       27.000000   \n",
       "max    1.073158e+06  10668.000000      2.920792       27.000000   \n",
       "\n",
       "       total_tokens_llama  total_tokens_omni         ratio  \n",
       "count        11000.000000       11000.000000  11000.000000  \n",
       "mean           593.797364         588.017000      1.004150  \n",
       "std            340.439513         334.197164      0.022444  \n",
       "min             87.000000          73.000000      0.754491  \n",
       "25%            256.000000         256.000000      0.994986  \n",
       "50%            559.000000         554.000000      1.005025  \n",
       "75%           1000.000000         979.000000      1.015152  \n",
       "max           1000.000000        1000.000000      1.397260  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='total_tokens_llama', ylabel='Count'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_df = sampled_data\n",
    "temp_df['ratio'] = sampled_data['total_tokens_llama']/sampled_data['total_tokens_omni']\n",
    "sns.histplot(data = sampled_data, x = 'total_tokens_llama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11000.000000\n",
       "mean       593.797364\n",
       "std        340.439513\n",
       "min         87.000000\n",
       "25%        256.000000\n",
       "50%        559.000000\n",
       "75%       1000.000000\n",
       "max       1000.000000\n",
       "Name: total_tokens_llama, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data['total_tokens_llama'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in sampled_data.iterrows():\n",
    "    text = row['content_html']\n",
    "    filename = row['file_name']\n",
    "    file_path = os.path.join('./data/silver_ocr', filename)\n",
    "\n",
    "    # Write the text to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonl_file(df, model, system_content, max_tokens, output_file):\n",
    "    \"\"\"\n",
    "    Create a JSONL file with the specified structure for each row in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    model (str): The model to be used in the 'body' of the JSON.\n",
    "    system_content (str): The content for the system message.\n",
    "    max_tokens (int): The max tokens value.\n",
    "    output_file (str): The path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as file:\n",
    "        for _, row in df.iterrows():\n",
    "            entry = {\n",
    "                \"custom_id\": f\"filename_{row['file_name']}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": system_content},\n",
    "                        {\"role\": \"user\", \"content\": row['content_html']}\n",
    "                    ],\n",
    "                    \"max_tokens\": max_tokens\n",
    "                }\n",
    "            }\n",
    "            # Write each JSON object as a separate line in the JSONL file\n",
    "            file.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Specify the arguments\n",
    "model = 'gpt-4o'\n",
    "system_content = \"You are an expert in recovery of corrupted OCR, the below text is from an English newspaper in the 1800's, please return in plain text, with appropriate spacing and line breaks\"\n",
    "max_tokens = 2200\n",
    "output_file = './data/output.jsonl'\n",
    "\n",
    "# Call the function with the DataFrame and arguments\n",
    "create_jsonl_file(sampled_data.reset_index().loc[0:20,:], model, system_content, max_tokens, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First example taken from the hansard \"Disfranchisement Of Sudbury\"\n",
    "\n",
    "https://hansard.parliament.uk/commons/1842-07-06/debates/bd9ca32b-d1b2-4337-bc00-32deed2899e7/DisfranchisementOfSudbury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silver_instructions_base = \"You are an expert in post-OCR correction of documents. Your task is to carefully examine the following text and correct any mistakes introduced by the OCR software. Do not write anything else than the corrected text.\"\n",
    "#silver_instructions_between = \"You are an expert in post-OCR correction of documents. Your task is to carefully examine the following text and correct any mistakes introduced by the OCR software. Do not write anything else than the corrected text. place the corrected text between the symbols '</corrected>'\"\n",
    "silver_instructions_historical = \"You are an expert in post-OCR correction of historical newspapers. Your task is to carefully examine the following text and correct any mistakes introduced by the OCR software. Do not write anything else than the corrected text.\"\n",
    "silver_instructions_ICL = \"\"\"You are an expert in post-OCR correction of documents. Your task is to carefully examine the following text and correct any mistakes introduced by the OCR software.Do not write anything else than the corrected text. \n",
    "As an example consider the following texts\n",
    "\n",
    "{\n",
    "  \"corrupted\": \"The populatlon of that hundrea amounteo to 24,069, ancl he bel1eved that if they ex tenclsd the borou#h, as he des1red, they woulcl secur@ an additlon to the prsent constituen€y of at least 1,000 votors.\"\n",
    "  \"recovered\": \"The population of that hundred amounted to 24,069, and he believed that if they extended the borough, as he desired, they would secure an addition to the present constituency of at least 1,000 voters.\",\n",
    "}\n",
    "\n",
    "{\n",
    "  \"corrupted\": \"Th3 park 1s a b3autiful pl@ce w1th lush gree.n l@wns, tall tre.es, an& a serene laKe wh3re v1sitors can .*-enjoy a peac3ful walk or a relax1ng boat ride...\"\n",
    "  \"recovered\": \"The park is a beautiful place with lush green lawns, tall trees, and a serene lake where visitors can enjoy a peaceful walk or a relaxing boat ride.\",\n",
    "}\n",
    "\n",
    "{\n",
    "  \"corrupted\": \"The res#aurant ser\\\\es a variet¥ of dis#es, includin fresh seafo9d, sa&ory s+eaks, and delici0us vegetarain opti0ns, al prep*red wth the finset ingrdients.\"\n",
    "  \"recovered\": \"The restaurant serves a variety of dishes, including fresh seafood, savory steaks, and delicious vegetarian options, all prepared with the finest ingredients.\",\n",
    "}\n",
    "\n",
    "You need only return the recovered text\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "silver_instructions_longprompt = \"\"\"You are an expert in post-OCR correction of documents. Your task is to carefully examine the following text and correct any mistakes introduced by the OCR software. Pay close attention to common OCR errors such as misrecognized characters, incorrect spacing, and punctuation issues.\n",
    "\n",
    "\n",
    "To complete this task, follow these steps:\n",
    "\n",
    "1. Read through the entire text to understand the context and identify potential errors.\n",
    "2. Correct any misrecognized characters, such as:\n",
    "   - Numbers mistaken for letters (e.g., '0' for 'O', '1' for 'I', '5' for 'S')\n",
    "   - Similar-looking letters (e.g., 'rn' for 'm', 'cl' for 'd')\n",
    "   - Special characters mistaken for letters or punctuation\n",
    "3. Fix any spacing issues, ensuring proper word separation and sentence structure.\n",
    "4. Correct punctuation errors, including misplaced or missing periods, commas, and quotation marks.\n",
    "5. Ensure proper capitalization, especially at the beginning of sentences and for proper nouns.\n",
    "6. Maintain the original formatting and structure of the text as much as possible.\n",
    "\n",
    "Provide your corrected version of the text without any additional explanations or comments. Your output should contain only the corrected text, preserving the original paragraph structure and line breaks.\n",
    "\n",
    "Begin your corrected text immediately after this instruction, without any introductory phrases or explanations.\"\"\"\n",
    "\n",
    "#create_jsonl_file(sampled_data.reset_index().loc[0:20,:], model, silver_instructions_base, max_tokens, './data/silver_instructions_base.jsonl')\n",
    "#create_jsonl_file(sampled_data.reset_index().loc[0:20,:], model, silver_instructions_between, max_tokens, './data/silver_instructions_between.jsonl') using this doesn't work as the model does not reliably return the symbols correctly.\n",
    "create_jsonl_file(sampled_data.reset_index().loc[0:20,:], model, silver_instructions_historical, max_tokens, './data/test_prompt_ready_to_batch/silver_instructions_historical.jsonl')\n",
    "create_jsonl_file(sampled_data.reset_index().loc[0:20,:], model, silver_instructions_ICL, max_tokens, './data/test_prompt_ready_to_batch/silver_instructions_ICL.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "  file=open('./data/silver_instructions_base.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_FnoK5q5bQOAKs9GfPOdRdlpi', completion_window='24h', created_at=1720984280, endpoint='/v1/chat/completions', input_file_id='file-bNxRuQZxubqvLpqiAgPpMffe', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1721070680, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'silver_instructions_base'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"silver_instructions_base\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_SDus5Sr3PQiFTMVyOLDGhBd2', completion_window='24h', created_at=1721735519, endpoint='/v1/chat/completions', input_file_id='file-zgzs5sRSm2vEJ4Y33iZdJedY', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1721735669, error_file_id=None, errors=None, expired_at=None, expires_at=1721821919, failed_at=None, finalizing_at=1721735665, in_progress_at=1721735519, metadata={'description': 'silver_instructions_longprompt'}, output_file_id='file-8ANGDnRRYSCe8bQc4ZhYvl3p', request_counts=BatchRequestCounts(completed=91, failed=0, total=91)),\n",
       " Batch(id='batch_BeCCUmTFEoc4hAv08gVctYT5', completion_window='24h', created_at=1721733210, endpoint='/v1/chat/completions', input_file_id='file-s2IM3wrz0wyRbgHtIBPg2uLf', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1721733272, error_file_id=None, errors=None, expired_at=None, expires_at=1721819610, failed_at=None, finalizing_at=1721733269, in_progress_at=1721733211, metadata={'description': 'silver_instructions_ICL'}, output_file_id='file-tvdqeNY4SChR33lYkaOt1aS5', request_counts=BatchRequestCounts(completed=91, failed=0, total=91))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = client.batches.list(limit=2)\n",
    "batch_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_transcript_oct_folder = './data/transcripts/transcription_raw_ocr'\n",
    "\n",
    "#These are referred to as \"gold\" as this clearly distinguishes the dataset from any dataframes called test or for testing things in general\n",
    "raw_gold_ocr_df = load_txt_files_to_df(raw_transcript_oct_folder)\n",
    "raw_gold_ocr_df['id'] = raw_gold_ocr_df['file_name'].str.split(\"_periodical\", expand = True)[0].str.replace(\"artid_\", \"\")\n",
    "\n",
    "enc = tiktoken.get_encoding('o200k_base')\n",
    "raw_gold_ocr_df['total_tokens'] = raw_gold_ocr_df['content_html'].apply(lambda x:len(enc.encode(x)))\n",
    "\n",
    "max_tokens = 4000\n",
    "\n",
    "\n",
    "create_jsonl_file(raw_gold_ocr_df, model, silver_instructions_historical, max_tokens, './data/test_prompt_ready_to_batch/silver_instructions_historical.jsonl')\n",
    "create_jsonl_file(raw_gold_ocr_df, model, silver_instructions_ICL, max_tokens, './data/test_prompt_ready_to_batch/silver_instructions_ICL.jsonl')\n",
    "\n",
    "create_jsonl_file(raw_gold_ocr_df, model, silver_instructions_longprompt, max_tokens, './data/test_prompt_ready_to_batch/silver_instructions_longprompt.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_SDus5Sr3PQiFTMVyOLDGhBd2', completion_window='24h', created_at=1721735519, endpoint='/v1/chat/completions', input_file_id='file-zgzs5sRSm2vEJ4Y33iZdJedY', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1721821919, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'silver_instructions_longprompt'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_file = client.files.create(\n",
    "  file=open('./data/test_prompt_ready_to_batch/silver_instructions_longprompt.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"silver_instructions_longprompt\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m file_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcontent(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile-NHwN8bGdp9xpveBt1rX8LF2V\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "file_response = client.files.content('file-NHwN8bGdp9xpveBt1rX8LF2V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_data(json_string, output_file):\n",
    "    \"\"\"\n",
    "    Save a string containing multiple JSON objects as a JSONL file.\n",
    "\n",
    "    Parameters:\n",
    "    json_string (str): The input string containing JSON objects.\n",
    "    output_file (str): The path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    # Split the string into individual JSON objects (assuming they are newline-separated)\n",
    "    json_objects = json_string.strip().split('\\n')\n",
    "    \n",
    "    with open(output_file, 'w') as file:\n",
    "        for json_object in json_objects:\n",
    "            # Convert the string to a dictionary to ensure it is valid JSON\n",
    "            json_dict = json.loads(json_object)\n",
    "            # Write the JSON object as a single line\n",
    "            file.write(json.dumps(json_dict) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_batch_data(file_response.text, './data/test_return.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_batch_to_dataframe(json_string):\n",
    "    \"\"\"\n",
    "    Extract 'custom_id', 'assistant' 'content', and 'usage' from a JSON string and create a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    json_string (str): The input string containing JSON objects.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the extracted data.\n",
    "    \"\"\"\n",
    "    json_objects = json_string.strip().split('\\n')\n",
    "    extracted_data = []\n",
    "\n",
    "    for json_object in json_objects:\n",
    "        data = json.loads(json_object)\n",
    "        custom_id = data['custom_id']\n",
    "        assistant_content = data['response']['body']['choices'][0]['message']['content']\n",
    "        usage = data['response']['body']['usage']\n",
    "        \n",
    "        row_data = {\n",
    "            'id': custom_id,\n",
    "            'corrected_content': assistant_content\n",
    "        }\n",
    "        \n",
    "        # Add the usage dictionary to the row data\n",
    "        row_data.update(usage)\n",
    "        \n",
    "        extracted_data.append(row_data)\n",
    "\n",
    "    return pd.DataFrame(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>corrected_content</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request-841530</td>\n",
       "      <td>MONOMANIA. ISCB—Oh? The Queen has \"popped\" at ...</td>\n",
       "      <td>1182</td>\n",
       "      <td>1062</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request-751411</td>\n",
       "      <td>* The Plague and the Printing Press: being a B...</td>\n",
       "      <td>322</td>\n",
       "      <td>158</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>request-871466</td>\n",
       "      <td>He performed upon divers of the foremost, who,...</td>\n",
       "      <td>1771</td>\n",
       "      <td>1668</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request-494321</td>\n",
       "      <td>be having necessary to tramp for the into hous...</td>\n",
       "      <td>672</td>\n",
       "      <td>573</td>\n",
       "      <td>1245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request-495935</td>\n",
       "      <td>\"Tomorrow we are going to pillage the archbish...</td>\n",
       "      <td>822</td>\n",
       "      <td>709</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>request-841528</td>\n",
       "      <td>because too much power was placed in the hands...</td>\n",
       "      <td>942</td>\n",
       "      <td>797</td>\n",
       "      <td>1739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>request-766218</td>\n",
       "      <td>^ ^ ^ ^ ^ ^ ¦ ¦ ¦¦ ¦¦¦¦¦¦¦ ^ ¦¦ ¦ ¦ ^ ^ ¦ ^ ^ ...</td>\n",
       "      <td>189</td>\n",
       "      <td>117</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>request-771187</td>\n",
       "      <td>Boo &amp; Co. and in lieu of Miss Braddon's new no...</td>\n",
       "      <td>1302</td>\n",
       "      <td>653</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>request-653700</td>\n",
       "      <td>have been designed: there may therefore be the...</td>\n",
       "      <td>562</td>\n",
       "      <td>456</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>request-802845</td>\n",
       "      <td>FOR THE USE OF OUR YOUNG FRIENDS. (Continued.)...</td>\n",
       "      <td>408</td>\n",
       "      <td>292</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                  corrected_content  \\\n",
       "0   request-841530  MONOMANIA. ISCB—Oh? The Queen has \"popped\" at ...   \n",
       "1   request-751411  * The Plague and the Printing Press: being a B...   \n",
       "2   request-871466  He performed upon divers of the foremost, who,...   \n",
       "3   request-494321  be having necessary to tramp for the into hous...   \n",
       "4   request-495935  \"Tomorrow we are going to pillage the archbish...   \n",
       "..             ...                                                ...   \n",
       "86  request-841528  because too much power was placed in the hands...   \n",
       "87  request-766218  ^ ^ ^ ^ ^ ^ ¦ ¦ ¦¦ ¦¦¦¦¦¦¦ ^ ¦¦ ¦ ¦ ^ ^ ¦ ^ ^ ...   \n",
       "88  request-771187  Boo & Co. and in lieu of Miss Braddon's new no...   \n",
       "89  request-653700  have been designed: there may therefore be the...   \n",
       "90  request-802845  FOR THE USE OF OUR YOUNG FRIENDS. (Continued.)...   \n",
       "\n",
       "    prompt_tokens  completion_tokens  total_tokens  \n",
       "0            1182               1062          2244  \n",
       "1             322                158           480  \n",
       "2            1771               1668          3439  \n",
       "3             672                573          1245  \n",
       "4             822                709          1531  \n",
       "..            ...                ...           ...  \n",
       "86            942                797          1739  \n",
       "87            189                117           306  \n",
       "88           1302                653          1955  \n",
       "89            562                456          1018  \n",
       "90            408                292           700  \n",
       "\n",
       "[91 rows x 5 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver_corrected = convert_batch_to_dataframe(file_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148369/2262283232.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  cer = load_metric(\"cer\")\n"
     ]
    }
   ],
   "source": [
    "cer = load_metric(\"cer\")\n",
    "wer = load_metric(\"wer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content_html</th>\n",
       "      <th>cer_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artid_841530_periodical_ns_issue_vm2-ncseprodu...</td>\n",
       "      <td>monomania.since oxford \"popped\" at the queen, ...</td>\n",
       "      <td>0.052698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artid_751411_periodical_pc_issue_tec_01051889_...</td>\n",
       "      <td>‘the plague and the printing press: being a bi...</td>\n",
       "      <td>0.485795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artid_871466_periodical_ns_issue_ns2_02101852_...</td>\n",
       "      <td>he performed upon diverse of the foremost, who...</td>\n",
       "      <td>0.045032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artid_494321_periodical_ewj_issue_ewj_01051860...</td>\n",
       "      <td>having to tramp into some dirty court in searc...</td>\n",
       "      <td>0.152632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artid_495935_periodical_ewj_issue_ewj_01011860...</td>\n",
       "      <td>tomorrow we are going to pillage the archbisho...</td>\n",
       "      <td>0.124153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>artid_841528_periodical_ns_issue_vm2-ncseprodu...</td>\n",
       "      <td>because too much power was placed in the hands...</td>\n",
       "      <td>0.059705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>artid_766218_periodical_pc_issue_tec_01031886_...</td>\n",
       "      <td>electrotypes. messrs. sampson low, marston, &amp; ...</td>\n",
       "      <td>0.753086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>artid_771187_periodical_pc_issue_tec_15091890_...</td>\n",
       "      <td>books and rumours of booksmiss braddon's new n...</td>\n",
       "      <td>0.705517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>artid_653700_periodical_mruc_issue_vm2-ncsepro...</td>\n",
       "      <td>have been designed: there may therefore be the...</td>\n",
       "      <td>0.061052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>artid_802845_periodical_t_issue_ttw_16051868_p...</td>\n",
       "      <td>woman's word-book.for the use of our young fri...</td>\n",
       "      <td>0.547142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_name  \\\n",
       "0   artid_841530_periodical_ns_issue_vm2-ncseprodu...   \n",
       "1   artid_751411_periodical_pc_issue_tec_01051889_...   \n",
       "2   artid_871466_periodical_ns_issue_ns2_02101852_...   \n",
       "3   artid_494321_periodical_ewj_issue_ewj_01051860...   \n",
       "4   artid_495935_periodical_ewj_issue_ewj_01011860...   \n",
       "..                                                ...   \n",
       "86  artid_841528_periodical_ns_issue_vm2-ncseprodu...   \n",
       "87  artid_766218_periodical_pc_issue_tec_01031886_...   \n",
       "88  artid_771187_periodical_pc_issue_tec_15091890_...   \n",
       "89  artid_653700_periodical_mruc_issue_vm2-ncsepro...   \n",
       "90  artid_802845_periodical_t_issue_ttw_16051868_p...   \n",
       "\n",
       "                                         content_html  cer_orig  \n",
       "0   monomania.since oxford \"popped\" at the queen, ...  0.052698  \n",
       "1   ‘the plague and the printing press: being a bi...  0.485795  \n",
       "2   he performed upon diverse of the foremost, who...  0.045032  \n",
       "3   having to tramp into some dirty court in searc...  0.152632  \n",
       "4   tomorrow we are going to pillage the archbisho...  0.124153  \n",
       "..                                                ...       ...  \n",
       "86  because too much power was placed in the hands...  0.059705  \n",
       "87  electrotypes. messrs. sampson low, marston, & ...  0.753086  \n",
       "88  books and rumours of booksmiss braddon's new n...  0.705517  \n",
       "89  have been designed: there may therefore be the...  0.061052  \n",
       "90  woman's word-book.for the use of our young fri...  0.547142  \n",
       "\n",
       "[91 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_transcript_oct_folder = \"./data/transcripts/transcription_files\"\n",
    "\n",
    "corrected_gold_ocr_df = load_txt_files_to_df(corrected_transcript_oct_folder)\n",
    "\n",
    "raw_ocr_df = load_txt_files_to_df(\"./data/transcripts/transcription_raw_ocr\")\n",
    "raw_ocr_df = raw_ocr_df.rename(columns={'content_html':'post_lm_text', 'file_name':'id'})\n",
    "\n",
    "corrected_gold_ocr_df = pre_evaluation_processing(raw_ocr_df, corrected_gold_ocr_df, post_lm_text= 'post_lm_text', gt_text = 'content_html' )\n",
    "corrected_gold_ocr_df = evaluate_model(df = corrected_gold_ocr_df, metric_obj = cer, gt_text = 'content_html', post_lm_text = 'post_lm_text')\n",
    "corrected_gold_ocr_df.rename(columns = {'cer':'cer_orig', 'id':'file_name'}, inplace=True)\n",
    "corrected_gold_ocr_df.drop(columns=['index', 'post_lm_text'], inplace=True)\n",
    "\n",
    "corrected_gold_ocr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_file = 'file-NHwN8bGdp9xpveBt1rX8LF2V'\n",
    "\n",
    "jsonl_file =  \"./data/batch_job_results_furniture.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_JUrnd5Vr4ULIoC9dVxZu29ve', completion_window='24h', created_at=1721732615, endpoint='/v1/chat/completions', input_file_id='file-2vSKGccZmNhYyAYIIFzjx6HL', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1721732669, error_file_id=None, errors=None, expired_at=None, expires_at=1721819015, failed_at=None, finalizing_at=1721732665, in_progress_at=1721732615, metadata={'description': 'silver_instructions_ICL'}, output_file_id='file-8EMaqLAJRHqOd8gs5SzggTG2', request_counts=BatchRequestCounts(completed=91, failed=0, total=91)),\n",
       " Batch(id='batch_dz5APpniHldq490XDCtPrQbS', completion_window='24h', created_at=1721732600, endpoint='/v1/chat/completions', input_file_id='file-7xe6NOtw0HiXXKKprCuSGwFd', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1721732667, error_file_id=None, errors=None, expired_at=None, expires_at=1721819000, failed_at=None, finalizing_at=1721732664, in_progress_at=1721732600, metadata={'description': 'silver_instructions_historical'}, output_file_id='file-8aGk8M9n5VIyQsySW7UqnnQc', request_counts=BatchRequestCounts(completed=91, failed=0, total=91))]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save_openai_batch_result('file-8aGk8M9n5VIyQsySW7UqnnQc',  './data/test_prompt_results/silver_instructions_historical.jsonl')\n",
    "save_openai_batch_result('file-8ANGDnRRYSCe8bQc4ZhYvl3p',  './data/test_prompt_results/silver_instructions_longprompt.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cer</th>\n",
       "      <th>ERP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.194177</td>\n",
       "      <td>0.559327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.212007</td>\n",
       "      <td>0.272929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.295848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.102807</td>\n",
       "      <td>0.564295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.365254</td>\n",
       "      <td>0.818007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.048387</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cer        ERP\n",
       "count  91.000000  91.000000\n",
       "mean    0.194177   0.559327\n",
       "std     0.212007   0.272929\n",
       "min     0.000000  -0.088000\n",
       "25%     0.009783   0.295848\n",
       "50%     0.102807   0.564295\n",
       "75%     0.365254   0.818007\n",
       "max     1.048387   1.000000"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver_instructions_between = convert_opanai_jsonl_to_df('./data/test_prompt_results/silver_instructions_ICL.jsonl')\n",
    "silver_instructions_between = pre_evaluation_processing(silver_instructions_between, corrected_gold_ocr_df, post_lm_text= 'post_lm_text', gt_text = 'content_html' )\n",
    "\n",
    "silver_instructions_between = evaluate_model(df = silver_instructions_between, metric_obj = cer, gt_text = 'content_html', post_lm_text = 'post_lm_text')\n",
    "silver_instructions_between['ERP'] = (silver_instructions_between['cer_orig'] - silver_instructions_between['cer'])/silver_instructions_between['cer_orig'] \n",
    "silver_instructions_between[['cer', 'ERP']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cer</th>\n",
       "      <th>ERP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.179128</td>\n",
       "      <td>0.599517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.195479</td>\n",
       "      <td>0.250826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.009184</td>\n",
       "      <td>0.425103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.094840</td>\n",
       "      <td>0.617108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.338043</td>\n",
       "      <td>0.826114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.758065</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cer        ERP\n",
       "count  91.000000  91.000000\n",
       "mean    0.179128   0.599517\n",
       "std     0.195479   0.250826\n",
       "min     0.000000  -0.031642\n",
       "25%     0.009184   0.425103\n",
       "50%     0.094840   0.617108\n",
       "75%     0.338043   0.826114\n",
       "max     0.758065   1.000000"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver_instructions_between = convert_opanai_jsonl_to_df('./data/test_prompt_results/silver_instructions_historical.jsonl')\n",
    "silver_instructions_between = pre_evaluation_processing(silver_instructions_between, corrected_gold_ocr_df, post_lm_text= 'post_lm_text', gt_text = 'content_html' )\n",
    "\n",
    "silver_instructions_between = evaluate_model(df = silver_instructions_between, metric_obj = cer, gt_text = 'content_html', post_lm_text = 'post_lm_text')\n",
    "silver_instructions_between['ERP'] = (silver_instructions_between['cer_orig'] - silver_instructions_between['cer'])/silver_instructions_between['cer_orig'] \n",
    "silver_instructions_between[['cer', 'ERP']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cer</th>\n",
       "      <th>ERP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.193581</td>\n",
       "      <td>0.550641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.212895</td>\n",
       "      <td>0.259574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001185</td>\n",
       "      <td>-0.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.011301</td>\n",
       "      <td>0.336447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.094840</td>\n",
       "      <td>0.514596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.367834</td>\n",
       "      <td>0.795190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.103226</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cer        ERP\n",
       "count  91.000000  91.000000\n",
       "mean    0.193581   0.550641\n",
       "std     0.212895   0.259574\n",
       "min     0.001185  -0.088000\n",
       "25%     0.011301   0.336447\n",
       "50%     0.094840   0.514596\n",
       "75%     0.367834   0.795190\n",
       "max     1.103226   0.947368"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver_instructions_between = convert_opanai_jsonl_to_df('./data/test_prompt_results/silver_instructions_longprompt.jsonl')\n",
    "silver_instructions_between = pre_evaluation_processing(silver_instructions_between, corrected_gold_ocr_df, post_lm_text= 'post_lm_text', gt_text = 'content_html' )\n",
    "\n",
    "silver_instructions_between = evaluate_model(df = silver_instructions_between, metric_obj = cer, gt_text = 'content_html', post_lm_text = 'post_lm_text')\n",
    "silver_instructions_between['ERP'] = (silver_instructions_between['cer_orig'] - silver_instructions_between['cer'])/silver_instructions_between['cer_orig'] \n",
    "silver_instructions_between[['cer', 'ERP']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset from SMH from trove\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
